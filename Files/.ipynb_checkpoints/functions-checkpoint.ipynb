{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import collections\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "import requests\n",
    "from urllib.parse import urlparse, urlsplit, urlunsplit\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtraction(features_file):\n",
    "    convertedArray = json.load(open(features_file, 'r'))\n",
    "    features = []\n",
    "    for i, j in enumerate(convertedArray):\n",
    "        if 'retweeted_status'in j and 'extended_tweet' in j['retweeted_status']:\n",
    "            features.append(j['retweeted_status']['extended_tweet']['full_text'])\n",
    "        elif 'retweeted_status' not in j and 'extended_tweet' in j:\n",
    "            features.append(j['extended_tweet']['full_text'])\n",
    "        else:\n",
    "            features.append(j['text'])\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelExtraction(label_file):\n",
    "#     csv_file = open(file)\n",
    "#     csv_reader = csv.reader(csv_file, delimiter = ' ')\n",
    "#     labels = []\n",
    "#     for row in csv_reader:\n",
    "#         labels.append(row[0])\n",
    "    labels = np.genfromtxt(label_file,dtype=None)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction(array, key):\n",
    "    reducedArray = []\n",
    "    for i, j in enumerate(array):\n",
    "        if len(reducedArray) == 0:\n",
    "            reducedArray.append(j)\n",
    "        else:\n",
    "            count = 0\n",
    "            for k in range(len(reducedArray)):\n",
    "                if a[k] != b[i]:\n",
    "                    count = count + 1\n",
    "            \n",
    "                if count == len(a):\n",
    "                    a.append(b[i])\n",
    "    \n",
    "    for i, j in enumerate(convertedArray):\n",
    "        if 'retweeted_status'in j and 'extended_tweet' in j['retweeted_status']:\n",
    "            features.append(j['retweeted_status']['extended_tweet']['full_text'])\n",
    "        elif 'retweeted_status' not in j and 'extended_tweet' in j:\n",
    "            features.append(j['extended_tweet']['full_text'])\n",
    "        else:\n",
    "            features.append(j['text'])\n",
    "    return reducedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCredentials():\n",
    "    app_key = \"jGVy1ilV55A7P24eJHuousM1b\"\n",
    "    app_secret = \"wrPOxGirrXEUQsU7Pk0jqaqt7nLYq10TmR0E6QdZPSlvvrktE8\"\n",
    "    oauth_token = \"1036998187880460289-K5YKVDBIlK5e1bsgsxzvmGk2z2BzTO\"\n",
    "    oauth_token_secret = \"ogxeyO9mgweKrFEOZhn638EvTVvZjn06ynVwviShsVOzZ\"\n",
    "    \n",
    "    return app_key, app_secret, oauth_token, oauth_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtraction2(features_file):\n",
    "    convertedArray = json.load(open(features_file, 'r'))\n",
    "    final = []\n",
    "    textFeatures = []\n",
    "    \n",
    "    for i, j in enumerate(convertedArray):\n",
    "        tempDict = {}\n",
    "        tempDict['id'] = j['id']\n",
    "        tempDict['date'] = j['created_at']\n",
    "        tempDict['username'] = j['user']['screen_name']\n",
    "        tempDict['hashtags'] = j['entities']['hashtags']\n",
    "        tempDict['user_mentions'] = j['entities']['user_mentions']\n",
    "        tempDict['favorites'] = j['favorite_count']\n",
    "        \n",
    "        if 'retweeted_status'in j and 'extended_tweet' in j['retweeted_status']:\n",
    "            textFeatures.append(j['retweeted_status']['extended_tweet']['full_text'])\n",
    "        elif 'retweeted_status' not in j and 'extended_tweet' in j:\n",
    "            textFeatures.append(j['extended_tweet']['full_text'])\n",
    "        else:\n",
    "            textFeatures.append(j['text'])\n",
    "        \n",
    "        final.append(tempDict)\n",
    "    \n",
    "    return final, textFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authorization(key):\n",
    "    if key == 'e' or 'E':\n",
    "        app_key = \"jGVy1ilV55A7P24eJHuousM1b\"\n",
    "        app_secret = \"wrPOxGirrXEUQsU7Pk0jqaqt7nLYq10TmR0E6QdZPSlvvrktE8\"\n",
    "        oauth_token = \"1036998187880460289-K5YKVDBIlK5e1bsgsxzvmGk2z2BzTO\"\n",
    "        oauth_token_secret = \"ogxeyO9mgweKrFEOZhn638EvTVvZjn06ynVwviShsVOzZ\"\n",
    "        return app_key, app_secret, oauth_token, oauth_token_secret\n",
    "    elif key == 'v' or 'V':\n",
    "        app_key = \"d\"\n",
    "    else:\n",
    "        print(\"Wrong identification key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cred_Processing(tweetsFile):\n",
    "    idRegEx = re.compile(r\".*ID=\")\n",
    "    endElRegEX = re.compile(r\"'.*\")\n",
    "    output = open(\"outputTweets.json\", \"w\")\n",
    "    \n",
    "    with open(tweetsFile, \"r\") as f:\n",
    "        header = f.readline()\n",
    "        \n",
    "        for line in f:\n",
    "            topicData = line.split(\"\\t\")\n",
    "            \n",
    "            topicKey = topicData[0]\n",
    "            topicTerms = topicData[1]\n",
    "            topicTweetCount = topicData[2]\n",
    "            tweetIdList = topicData[3]\n",
    "            \n",
    "            print(topicKey)\n",
    "            \n",
    "            realTweetsIds = []\n",
    "            \n",
    "            idElements = tweetIdList.split(\"),\")\n",
    "            for element in idElements:\n",
    "                elArr = element.split(\",\")\n",
    "                idEl = list(filter(lambda x: \"ID\" in x, elArr))[0]\n",
    "                idEl = idRegEx.sub(\"\", idEl)\n",
    "                idEl = endElRegEX.sub(\"\", idEl)\n",
    "                \n",
    "                realTweetsIds.append(int(idEl))\n",
    "                \n",
    "            realTweetsIds = list(set(realTweetsIds))\n",
    "            \n",
    "            topicMap = {\n",
    "                \"key\" : topicKey,\n",
    "                \"terms\" : topicTerms.split(\",\"),\n",
    "                \"count\" : topicTweetCount, \n",
    "                \"tweets\" : realTweetsIds\n",
    "            }\n",
    "            \n",
    "            json.dump(topicMap, output, sort_keys=True)\n",
    "            output.write(\"\\n\")\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_processing(ratingFile, tweetsFile):\n",
    "    tweetsMap = {}\n",
    "    \n",
    "    with open(tweetsFile, \"r\") as f:\n",
    "        for line in f:\n",
    "            tweetData = json.loads(line)\n",
    "            tweetsMap[tweetData[\"key\"]] = tweetData\n",
    "            \n",
    "    output = open(r\"C:\\Users\\vdoan\\Documents\\College\\SummerResearch\\SmResearch\\Data\\CREDBANK\\finalOutput.json\", \"w\")\n",
    "    \n",
    "    with open(ratingFile, \"r\") as f:\n",
    "        header = f.readline()\n",
    "        \n",
    "        for line in f:\n",
    "            topicData = line.split(\"\\t\")\n",
    "            topicKey = topicData[0]\n",
    "            topicTerms = topicData[1]\n",
    "            ratings = topicData[2]\n",
    "            reasons = topicData[3]\n",
    "            \n",
    "            try:\n",
    "                ratings = list(map(lambda x: int(x.strip().replace(\"'\", \"\")), ratings.replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")))\n",
    "                ratings = np.array(ratings)\n",
    "                tweetsMap[topicKey][\"mean\"] = np.mean(ratings)\n",
    "                print(\"Inserting ratings for {}\".format(topicKey))\n",
    "                tweetsMap[topicKey][\"ratings\"] = ratings.tolist()\n",
    "                print(\"Success\")\n",
    "                print(\"Inserting mean for {}\".format(topicKey))\n",
    "                tweetsMap[topicKey][\"mean\"] = np.mean(ratings)\n",
    "                print(\"Success\")\n",
    "                topicMap = tweetsMap[topicKey]\n",
    "                print(topicMap[\"key\"], topicMap[\"mean\"])\n",
    "                json.dump(topicMap, output, sort_keys=True)\n",
    "                output.write(\"\\n\")\n",
    "            except:\n",
    "                print(\"{} is missing.\".format(topicKey))\n",
    "            \n",
    "            \n",
    "            \n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryConversion(outputFile):\n",
    "    labels = {}\n",
    "    with open(outputFile, 'r') as f:\n",
    "        for line in f:\n",
    "            tweet = json.loads(line)\n",
    "            if(tweet['mean'] >= 1.9):\n",
    "                labels[tweet['key']] = 1\n",
    "            elif(tweet['mean'] <= 1.467):\n",
    "                labels[tweet['key']] = 0\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Retweet and date\n",
    "def singleMessageFeatureExtraction(tweet_json):\n",
    "    #print(tweet_json)\n",
    "    retweets = 0\n",
    "    try:\n",
    "        retweets = tweet_json[\"tweet\"][\"retweet_status\"]\n",
    "        retweets = 1\n",
    "    except:\n",
    "        retweets = 0\n",
    "    date = tweet_json[\"tweet\"][\"created_at\"].split(\" \")[0]\n",
    "    dates = []\n",
    "    if date == \"Mon\":\n",
    "        dates = [1,0,0,0,0,0,0]\n",
    "    elif date == \"Tue\":\n",
    "        dates = [0,1,0,0,0,0,0]\n",
    "    elif date == \"Wed\":\n",
    "        dates = [0,0,1,0,0,0,0]\n",
    "    elif date == \"Thu\":\n",
    "        dates = [0,0,0,1,0,0,0]\n",
    "    elif date == \"Fri\":\n",
    "        dates = [0,0,0,0,1,0,0]\n",
    "    elif date == \"Sat\":\n",
    "        dates = [0,0,0,0,0,1,0]\n",
    "    elif date == \"Sun\":\n",
    "        dates = [0,0,0,0,0,0,1]\n",
    "    return retweets, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unshorten_url(url):\n",
    "    return requests.head(url, allow_redirects=True).url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messageFeatureExtraction(tweets, tweet_json, threshold):\n",
    "    tweetsFeatures = None\n",
    "    np.array(tweetsFeatures)\n",
    "    count = 0\n",
    "    for tweet in tweets:\n",
    "        print(\"Starting feature extraction for tweet {} of {}\".format(count, len(tweets)))\n",
    "        indiTweetFeature = []\n",
    "        #Length of characters 1\n",
    "        print(\"Adding Length of charactrs\")\n",
    "        indiTweetFeature.append(len(tweet))\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "        \n",
    "        print(\"Adding words\")\n",
    "        #Length of words 2\n",
    "        indiTweetFeature.append(len(tweet.split(\" \")))\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "        \n",
    "        print(\"Adding question mark\")\n",
    "        #Contains question mark 3\n",
    "        results = collections.Counter(tweet)\n",
    "        if(results['?'] > 1):\n",
    "            indiTweetFeature.append(1)\n",
    "        else:\n",
    "            indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "\n",
    "        print('Adding exclamation mark')\n",
    "        #Contains exclamation 4\n",
    "        if(results['!'] > 1):\n",
    "            indiTweetFeature.append(1)\n",
    "        else:\n",
    "            indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "\n",
    "        print(\"Adding smiles\")\n",
    "        #Contains emoticon smile 5\n",
    "        emojis = \"ðŸ˜Š\"\n",
    "        indiTweetFeature.append(tweet.count(emojis))\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "\n",
    "        print(\"!?\")\n",
    "        #Contains multiple question or exclamation marks 6\n",
    "        if results['?'] and results['!'] > 1:\n",
    "            indiTweetFeature.append(1)\n",
    "        else:\n",
    "            indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "\n",
    "        print(\"Adding first person pronouns\")\n",
    "        #Contains pronoun first, sceond, third 7\n",
    "        first_pronouns = [\"i\", \"we\"]\n",
    "        tweetSplit = tweet.split(\" \")\n",
    "        for x in range(len(tweetSplit)):\n",
    "            if(tweetSplit[x].lower() in first_pronouns):\n",
    "                indiTweetFeature.append(1)\n",
    "                break;\n",
    "            if(x == len(tweetSplit)-1):\n",
    "                indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "        print(\"Adding second person pronouns\")\n",
    "        second_pronouns = [\"you\"]\n",
    "        tweetSplit = tweet.split(\" \")\n",
    "        for x in range(len(tweetSplit)):\n",
    "            if(tweetSplit[x].lower() in second_pronouns):\n",
    "                indiTweetFeature.append(1)\n",
    "                break;\n",
    "            if(x == len(tweetSplit)-1):\n",
    "                indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "        print(\"Adding third person pronouns\")\n",
    "        third_pronouns = [\"he\", \"him,\" \"she\", \"her\", \"they\", \"them\", \"it\"]\n",
    "\n",
    "        tweetSplit = tweet.split(\" \")\n",
    "        for x in range(len(tweetSplit)):\n",
    "            if(tweetSplit[x].lower() in third_pronouns):\n",
    "                indiTweetFeature.append(1)\n",
    "                break;\n",
    "            if(x == len(tweetSplit)-1):\n",
    "                indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "       #print(indiTweetFeature)   \n",
    "        \n",
    "        print(\"Adding uppercase\")\n",
    "        #Count uppercase letters 8\n",
    "        upperLetterCount = 0\n",
    "        for letter in tweet:\n",
    "            if(letter.isupper()):\n",
    "                upperLetterCount += 1\n",
    "        indiTweetFeature.append(upperLetterCount)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "\n",
    "        print(\"Adding url\")\n",
    "        #Number of URLs 9\n",
    "        url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+] |[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', tweet) \n",
    "        indiTweetFeature.append(len(url))\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "        \n",
    "        #Contains popular domain top 100,1000,10000\n",
    "        print(\"Adding popular domain\")\n",
    "        file = pd.read_csv('../../Data/top-1m.csv')\n",
    "        try:\n",
    "            urls = tweet_json[count]['tweet']['entities']['urls']\n",
    "        except:\n",
    "            print(tweet_json[count]['tweet'])\n",
    "        top100 = 0\n",
    "        top1000 = 0\n",
    "        top10000 = 0\n",
    "\n",
    "        for url in urls:\n",
    "            urlParsed = None\n",
    "            rank = None\n",
    "            try:\n",
    "                split_url = urlsplit(url['expanded_url'])   \n",
    "                shortUrl = ''\n",
    "                if(split_url.netloc[:4] == 'www.'):\n",
    "                    shortUrl = split_url.netloc[4:]\n",
    "                else:\n",
    "                    shortUrl = split_url.netloc\n",
    "                print(shortUrl)\n",
    "                print(file.loc[file['site'] == shortUrl]['rank'])\n",
    "                rank = int(file.loc[file['site'] == split_url.netloc]['rank'])\n",
    "            except Exception as e:\n",
    "                rank = 10001\n",
    "            if rank <= 100:\n",
    "                top100 = 1\n",
    "            if rank <= 1000:\n",
    "                top1000 = 1\n",
    "            if rank <= 10000:\n",
    "                top10000 = 1\n",
    "        \n",
    "        indiTweetFeature.append(top100)\n",
    "        indiTweetFeature.append(top1000)\n",
    "        indiTweetFeature.append(top10000)\n",
    "                \n",
    "        print(\"Adding mention\")\n",
    "        #Contains user mention 10\n",
    "        result = re.findall(\"(^|[^@\\w])@(\\w{1,15})\", tweet)\n",
    "        if(len(result) >= threshold):\n",
    "            indiTweetFeature.append(1)\n",
    "        else:\n",
    "            indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "        #print(indiTweetFeature)\n",
    "    \n",
    "        # Length of hashtags 11\n",
    "        print(\"Adding hashtags\")\n",
    "        hashtags = [i  for i in tweet.split() if i.startswith(\"#\") ]\n",
    "        indiTweetFeature.append(len(hashtags))\n",
    "        #print(indiTweetFeature)\n",
    "     \n",
    "        #Contains stock symbol 12\n",
    "        print(\"Addings stocks\")\n",
    "        file = open('../../Data/nasdaqlisted.txt', 'r')\n",
    "        filecontents = file.readlines()\n",
    "        stock_symbols = []\n",
    "        for line in filecontents:\n",
    "            splitline = line.split(\"|\")\n",
    "            stock_symbols.append(splitline[0])\n",
    "            \n",
    "        del stock_symbols[0]\n",
    "        \n",
    "        stockCount = 0\n",
    "        for word in tweetSplit:\n",
    "            if(word in stock_symbols):\n",
    "                stockCount += 1\n",
    "        \n",
    "        if(stockCount > 0):\n",
    "            indiTweetFeature.append(1)\n",
    "        else:\n",
    "            indiTweetFeature.append(0)\n",
    "        #print(indiTweetFeature)\n",
    "                \n",
    "        retweets, date = singleMessageFeatureExtraction(tweet_json[count])\n",
    "        print(\"Adding retweets\")\n",
    "        indiTweetFeature.append(retweets)\n",
    "        #print(indiTweetFeature)\n",
    "        print(\"Adding date\")\n",
    "        indiTweetFeature = indiTweetFeature + date\n",
    "        #print(indiTweetFeature)\n",
    "        \n",
    "        print(\"Adding sentiment\")\n",
    "        #Sentiment 13, 14, 15\n",
    "        positiveWords = 0\n",
    "        negativeWords= 0\n",
    "    \n",
    "        tweetSentiment = TextBlob(tweet)\n",
    "        sentimentScore = tweetSentiment.sentiment[0]\n",
    "    \n",
    "        for word in tweetSentiment:\n",
    "            word = TextBlob(word)\n",
    "            if(word.sentiment.polarity) > 0:\n",
    "                positiveWords = positiveWords + 1\n",
    "            elif(word.sentiment.polarity) < 0:\n",
    "                negativeWords = negativeWords + 1\n",
    "        indiTweetFeature.append(sentimentScore)\n",
    "        #print(indiTweetFeature)\n",
    "        \n",
    "        #print(indiTweetFeature)\n",
    "        indiTweetFeature = [indiTweetFeature]\n",
    "        if(count == 0):\n",
    "            #print(\"hello\")\n",
    "            tweetsFeatures = indiTweetFeature\n",
    "            #print(tweetsFeatures.shape)\n",
    "            print(\"Length of array: {}\".format(len(tweetsFeatures[count])))\n",
    "        else:\n",
    "            tweetsFeatures = np.append(tweetsFeatures, indiTweetFeature, axis = 0)\n",
    "            print(tweetsFeatures.shape)\n",
    "        #print(len(indiTweetFeature))\n",
    "        print(\"Finished feature extraction for tweet {} of {}\".format(count, len(tweets)))\n",
    "        count += 1\n",
    "        \n",
    "#         if count == 3:\n",
    "#             break;\n",
    "    return tweetsFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def topicFeatureExtraction():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicFeatureExtraction(topics, threshold):\n",
    "    \n",
    "    all_features = None\n",
    "    np.array(all_features)\n",
    "    \n",
    "    first_pronouns = set([\"i\", \"we\"])\n",
    "    second_pronouns = set([\"you\"])\n",
    "    third_pronouns = set([\"he\", \"him,\" \"she\", \"her\", \"they\", \"them\", \"it\"])\n",
    "    \n",
    "    for topic in topics: \n",
    "        print(\"Starting topic feature extraction\")\n",
    "        print(\"Current topic: \", topic)\n",
    "        current_topic = topics[topic]\n",
    "        \n",
    "        \n",
    "        #prop for proportion, fr for frequency \n",
    "        int total_no_tweets = len(current_topic)\n",
    "        \n",
    "        int fr_quest_mark = 0\n",
    "        int fr_excl_mark = 0\n",
    "        \n",
    "        int fr_emot_smile = 0 \n",
    "    \n",
    "        int fr_tweets_hashtag = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        int fr_pron_first = 0\n",
    "        int fr_pron_sec = 0\n",
    "        int fr_pron_third = 0\n",
    "        \n",
    "        #Polarity = Average sentiment score of tweets \n",
    "        int avg_polarity = 0 \n",
    "        int disagreement = 0\n",
    "        \n",
    "        for tweet in current_topic: \n",
    "            \n",
    "            split_tweet = split(tweet)\n",
    "            split_tweet_word = set(tweet.split(\" \"))\n",
    "\n",
    "            if '?' in split_tweet:\n",
    "                fr_quest_mark += 1\n",
    "            if '!' in split_tweet:\n",
    "                fr_excl_mark += 1\n",
    "            if 'ðŸ˜Š' in split_tweet:\n",
    "                fr_emot_smile += 1\n",
    "            if '#' in split_tweet:\n",
    "                fr_tweets_hashtag += 1\n",
    "            \n",
    "            \n",
    "            if (first_pronounces & split_tweet_word):\n",
    "                fr_pron_first += 1\n",
    "            if (second_pronounces & split_tweet_word):\n",
    "                fr_pron_sec += 1\n",
    "            if (third_pronounces & split_tweet_word):\n",
    "                fr_pron_third += 1 \n",
    "                \n",
    "            \n",
    "            tweetSentiment = TextBlob(tweet)\n",
    "            sentimentScore = tweetSentiment.sentiment[0]\n",
    "            disagreementScore = tweetSentiment.sentiment[1]\n",
    "            avg_polarity += sentimentScore\n",
    "            disagreement += disagreementScore\n",
    "                \n",
    "                \n",
    "                \n",
    "        int prop_quest_mark = fr_quest_mark / total_no_tweets\n",
    "        int prop_excl_mark = fr_excl_mark / total_no_tweets\n",
    "        int prop_emot_smile = fr_emot_smile / total_no_tweets\n",
    "        int prop_tweets_hashtag = fr_tweets_hashtag / total_no_tweets\n",
    "\n",
    "        \n",
    "        int prop_pron_first = fr_pron_first / total_no_tweets\n",
    "        int prop_pron_sec = fr_pron_sec / total_no_tweets\n",
    "        int prop_pron_third = fr_pron_third / total_no_tweets\n",
    "        \n",
    "        avg_polarity = avg_polarity / total_no_tweets\n",
    "        \n",
    "           \n",
    "        int disagreement = 0\n",
    "    \n",
    "        all_features.append(avg_polarity)\n",
    "        all_features.append(objectivity)\n",
    "        all_features.append(disagreement)\n",
    "        all_features.append(fr_quest_mark)\n",
    "        all_features.append(prop_quest_mark)\n",
    "        all_features.append(fr_excl_mark)\n",
    "        all_features.append(prop_excl_mark)\n",
    "        all_features.append(fr_emot_smile)\n",
    "        all_features.append(prop_emot_smile)\n",
    "        all_features.append(fr_pron_first)\n",
    "        all_features.append(prop_pron_first)\n",
    "        all_features.append(fr_pron_sec)\n",
    "        all_features.append(prop_pron_sec)\n",
    "        all_features.append(fr_pron_third)\n",
    "        all_features.append(prop_pron_third)\n",
    "\n",
    "    return all_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userFeatureExtraction(topics, threshold):\n",
    "    all_features = None\n",
    "    np.array(all_features)\n",
    "    \n",
    "    #Average account age format : \"created_at\": \"Fri Jun 26 07:47:06 +0000 2009\"\n",
    "\n",
    "\n",
    "    #When an account was created and the relevant tweet was authored\n",
    "    \n",
    "    \n",
    "    #Network Density\n",
    "\n",
    "    for topic in topics:\n",
    "        #Avg date create\n",
    "        int avg_date_user_create = 0\n",
    "        \n",
    "        #Average follower count\n",
    "        int avg_follower_cnt = 0\n",
    "    \n",
    "    \n",
    "        #Average friend count\n",
    "        int avg_friend_cnt = 0 \n",
    "    \n",
    "        #Average authored status count \n",
    "        int avg_aut_stat_cnt = 0\n",
    "    \n",
    "        #Frequency of verified author \n",
    "        int fr_veri_aut = 0 \n",
    "    \n",
    "        #Author of the First Tweet is Verified\n",
    "        int fr_first_veri = 0\n",
    "        current_topic = topics[topic]\n",
    "        no_tweet = len(topic)\n",
    "        \n",
    "        int avg_date_tweet_create = 0\n",
    "        \n",
    "        #TODO: how to format this?\n",
    "        for tweet in current_topic:\n",
    "            \n",
    "            #Average account age format : \"created_at\": \"Fri Jun 26 07:47:06 +0000 2009\"\n",
    "            user_created_string = current_topic['user']['created_at']\n",
    "            tweet_created_string = current_topic['created_at']\n",
    "            user_created_string_list = user_created_string.split(\" \")\n",
    "            tweet_created_string_list = tweet_created_string.split(\" \")\n",
    "            int day_user = user_created_string_list[2]\n",
    "            int month_user = 0\n",
    "            int year_user = user_created_string_list[5]\n",
    "            \n",
    "            int day_tweet = tweet_created_string_list[2]\n",
    "            int month_tweet = 0\n",
    "            int year_tweet = tweet_created_string_list[5]\n",
    "\n",
    "            if (user_created_string_list[1] == 'Jan'):\n",
    "                month = 1\n",
    "            elif (user_created_string_list[1] == 'Feb'):\n",
    "                month = 2\n",
    "            elif (user_created_string_list[1] == 'Mar'):\n",
    "                month = 3\n",
    "            elif (user_created_string_list[1] == 'Apr'):\n",
    "                month = 4\n",
    "            elif (user_created_string_list[1] == 'May'):\n",
    "                month = 5\n",
    "            elif (user_created_string_list[1] == 'Jun'):\n",
    "                month = 6\n",
    "            elif (user_created_string_list[1] == 'Jul'):\n",
    "                month = 7\n",
    "            elif (user_created_string_list[1] == 'Aug'):\n",
    "                month = 8\n",
    "            elif (user_created_string_list[1] == 'Sep'):\n",
    "                month = 9\n",
    "            elif (user_created_string_list[1] == 'Oct'):\n",
    "                month = 10\n",
    "            elif (user_created_string_list[1] == 'Nov'):\n",
    "                month = 11\n",
    "            elif (user_created_string_list[1] == 'Dec'):\n",
    "                month = 12\n",
    "                \n",
    "                \n",
    "            if (tweet_created_string_list[1] == 'Jan'):\n",
    "                month = 1\n",
    "            elif (tweet_created_string_list[1] == 'Feb'):\n",
    "                month = 2\n",
    "            elif (tweet_created_string_list[1] == 'Mar'):\n",
    "                month = 3\n",
    "            elif (tweet_created_string_list[1] == 'Apr'):\n",
    "                month = 4\n",
    "            elif (tweet_created_string_list[1] == 'May'):\n",
    "                month = 5\n",
    "            elif (tweet_created_string_list[1] == 'Jun'):\n",
    "                month = 6\n",
    "            elif (tweet_created_string_list[1] == 'Jul'):\n",
    "                month = 7\n",
    "            elif (tweet_created_string_list[1] == 'Aug'):\n",
    "                month = 8\n",
    "            elif (tweet_created_string_list[1] == 'Sep'):\n",
    "                month = 9\n",
    "            elif (tweet_created_string_list[1] == 'Oct'):\n",
    "                month = 10\n",
    "            elif (tweet_created_string_list[1] == 'Nov'):\n",
    "                month = 11\n",
    "            elif (tweet_created_string_list[1] == 'Dec'):\n",
    "                month = 12\n",
    "            \n",
    "            user_created_date = date(year_user,month_user,day_user)\n",
    "            tweet_created_date = date(year_tweet,month_tweet,day_tweet)\n",
    "            current_date = datetime.datetime.today()\n",
    "            user_delta = current_date - user_created_date\n",
    "            tweet_delta = current_date - tweet_created_date\n",
    "            avg_date_user_create += user_delta.days\n",
    "            avg_date_tweet_create += tweet_delta.days\n",
    "            \n",
    "            \n",
    "            \n",
    "            int follower_count = current_topic['user']['followers_count']\n",
    "        \n",
    "            int friend_count = current_topic['user']['friends_count']\n",
    "        \n",
    "            int aut_stat_count = current_topic['user']['statuses_count']\n",
    "        \n",
    "            #0 for false, 1 for true\n",
    "            int is_verified = 0\n",
    "        \n",
    "            if (current_topic['user']['verified'] == 'true'):\n",
    "                is_verified = 1\n",
    "            else:\n",
    "                is_verified = 0\n",
    "            \n",
    "            if (current_topic['in_reply_to_status_id'] != 'null') && (current_topic['user']['verified'] == 'true':\n",
    "                fr_first_veri += 1\n",
    "            \n",
    "                                                                      \n",
    "            avg_follower_cnt += follower_count\n",
    "            avg_friend_cnt += friend_count\n",
    "            avg_aut_stat_cnt += aut_stat_count\n",
    "            fr_veri_aut += is_verified                                                              \n",
    "        avg_date_user_create = avg_date_user_create / no_tweet                                                              \n",
    "        avg_follower_cnt = avg_follower_cnt / no_tweet\n",
    "        avg_friend_cnt = avg_friend_cnt / no_tweet\n",
    "        avg_aut_stat_cnt = avg_aut_stat_cnt / no_tweet\n",
    "        avg_date_tweet_create = avg_date_tweet_create / no_tweet                                                    \n",
    "        \n",
    "        current_topic_feature = None\n",
    "        np.array(current_topic_feature)\n",
    "        \n",
    "        current_topic_feature.append(avg_date_user_create)                                                              \n",
    "        current_topic_feature.append(avg_follower_cnt)\n",
    "        current_topic_feature.append(avg_friend_cnt)\n",
    "        current_topic_feature.append(avg_aut_stat_cnt)\n",
    "        current_topic_feature.append(fr_veri_aut)\n",
    "        current_topic_feature.append(fr_first_veri)\n",
    "        current_topic_feature.append()                                                              \n",
    "                                                                      \n",
    "        all_features.append(current_topic_feature)                                                              \n",
    "\n",
    "           \n",
    "        \n",
    "    return all_features \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def propagationFeatureExtraction():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

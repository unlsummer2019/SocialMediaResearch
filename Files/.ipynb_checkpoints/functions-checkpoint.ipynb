{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "import collections\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from urllib.parse import urlparse, urlsplit, urlunsplit\n",
    "from time import sleep\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtraction(features_file):\n",
    "    convertedArray = json.load(open(features_file, 'r'))\n",
    "    features = []\n",
    "    for i, j in enumerate(convertedArray):\n",
    "        if 'retweeted_status'in j and 'extended_tweet' in j['retweeted_status']:\n",
    "            features.append(j['retweeted_status']['extended_tweet']['full_text'])\n",
    "        elif 'retweeted_status' not in j and 'extended_tweet' in j:\n",
    "            features.append(j['extended_tweet']['full_text'])\n",
    "        else:\n",
    "            features.append(j['text'])\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelExtraction(label_file):\n",
    "#     csv_file = open(file)\n",
    "#     csv_reader = csv.reader(csv_file, delimiter = ' ')\n",
    "#     labels = []\n",
    "#     for row in csv_reader:\n",
    "#         labels.append(row[0])\n",
    "    labels = np.genfromtxt(label_file,dtype=None)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction(array, key):\n",
    "    reducedArray = []\n",
    "    for i, j in enumerate(array):\n",
    "        if len(reducedArray) == 0:\n",
    "            reducedArray.append(j)\n",
    "        else:\n",
    "            count = 0\n",
    "            for k in range(len(reducedArray)):\n",
    "                if a[k] != b[i]:\n",
    "                    count = count + 1\n",
    "            \n",
    "                if count == len(a):\n",
    "                    a.append(b[i])\n",
    "    \n",
    "    for i, j in enumerate(convertedArray):\n",
    "        if 'retweeted_status'in j and 'extended_tweet' in j['retweeted_status']:\n",
    "            features.append(j['retweeted_status']['extended_tweet']['full_text'])\n",
    "        elif 'retweeted_status' not in j and 'extended_tweet' in j:\n",
    "            features.append(j['extended_tweet']['full_text'])\n",
    "        else:\n",
    "            features.append(j['text'])\n",
    "    return reducedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCredentials():\n",
    "    app_key = \"jGVy1ilV55A7P24eJHuousM1b\"\n",
    "    app_secret = \"wrPOxGirrXEUQsU7Pk0jqaqt7nLYq10TmR0E6QdZPSlvvrktE8\"\n",
    "    oauth_token = \"1036998187880460289-K5YKVDBIlK5e1bsgsxzvmGk2z2BzTO\"\n",
    "    oauth_token_secret = \"ogxeyO9mgweKrFEOZhn638EvTVvZjn06ynVwviShsVOzZ\"\n",
    "    \n",
    "    return app_key, app_secret, oauth_token, oauth_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtraction2(features_file):\n",
    "    convertedArray = json.load(open(features_file, 'r'))\n",
    "    final = []\n",
    "    textFeatures = []\n",
    "    \n",
    "    for i, j in enumerate(convertedArray):\n",
    "        tempDict = {}\n",
    "        tempDict['id'] = j['id']\n",
    "        tempDict['date'] = j['created_at']\n",
    "        tempDict['username'] = j['user']['screen_name']\n",
    "        tempDict['hashtags'] = j['entities']['hashtags']\n",
    "        tempDict['user_mentions'] = j['entities']['user_mentions']\n",
    "        tempDict['favorites'] = j['favorite_count']\n",
    "        \n",
    "        if 'retweeted_status'in j and 'extended_tweet' in j['retweeted_status']:\n",
    "            textFeatures.append(j['retweeted_status']['extended_tweet']['full_text'])\n",
    "        elif 'retweeted_status' not in j and 'extended_tweet' in j:\n",
    "            textFeatures.append(j['extended_tweet']['full_text'])\n",
    "        else:\n",
    "            textFeatures.append(j['text'])\n",
    "        \n",
    "        final.append(tempDict)\n",
    "    \n",
    "    return final, textFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authorization(key):\n",
    "    if key == 'e' or 'E':\n",
    "        app_key = \"jGVy1ilV55A7P24eJHuousM1b\"\n",
    "        app_secret = \"wrPOxGirrXEUQsU7Pk0jqaqt7nLYq10TmR0E6QdZPSlvvrktE8\"\n",
    "        oauth_token = \"1036998187880460289-K5YKVDBIlK5e1bsgsxzvmGk2z2BzTO\"\n",
    "        oauth_token_secret = \"ogxeyO9mgweKrFEOZhn638EvTVvZjn06ynVwviShsVOzZ\"\n",
    "        return app_key, app_secret, oauth_token, oauth_token_secret\n",
    "    elif key == 'v' or 'V':\n",
    "        app_key = \"d\"\n",
    "    else:\n",
    "        print(\"Wrong identification key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cred_Processing(tweetsFile):\n",
    "    idRegEx = re.compile(r\".*ID=\")\n",
    "    endElRegEX = re.compile(r\"'.*\")\n",
    "    output = open(\"outputTweets.json\", \"w\")\n",
    "    \n",
    "    with open(tweetsFile, \"r\") as f:\n",
    "        header = f.readline()\n",
    "        \n",
    "        for line in f:\n",
    "            topicData = line.split(\"\\t\")\n",
    "            \n",
    "            topicKey = topicData[0]\n",
    "            topicTerms = topicData[1]\n",
    "            topicTweetCount = topicData[2]\n",
    "            tweetIdList = topicData[3]\n",
    "            \n",
    "            print(topicKey)\n",
    "            \n",
    "            realTweetsIds = []\n",
    "            \n",
    "            idElements = tweetIdList.split(\"),\")\n",
    "            for element in idElements:\n",
    "                elArr = element.split(\",\")\n",
    "                idEl = list(filter(lambda x: \"ID\" in x, elArr))[0]\n",
    "                idEl = idRegEx.sub(\"\", idEl)\n",
    "                idEl = endElRegEX.sub(\"\", idEl)\n",
    "                \n",
    "                realTweetsIds.append(int(idEl))\n",
    "                \n",
    "            realTweetsIds = list(set(realTweetsIds))\n",
    "            \n",
    "            topicMap = {\n",
    "                \"key\" : topicKey,\n",
    "                \"terms\" : topicTerms.split(\",\"),\n",
    "                \"count\" : topicTweetCount, \n",
    "                \"tweets\" : realTweetsIds\n",
    "            }\n",
    "            \n",
    "            json.dump(topicMap, output, sort_keys=True)\n",
    "            output.write(\"\\n\")\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_processing(ratingFile, tweetsFile):\n",
    "    tweetsMap = {}\n",
    "    \n",
    "    with open(tweetsFile, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweetData = json.loads(line)\n",
    "                tweetsMap[tweetData[\"key\"]] = tweetData\n",
    "            except:\n",
    "                print(\"Error\")\n",
    "            \n",
    "    output = open(r\"/media/eric/TOSHIBA EXT/University/Research/Data/CREDBANK/finalOutput.json\", \"w\")\n",
    "    \n",
    "    with open(ratingFile, \"r\") as f:\n",
    "        header = f.readline()\n",
    "        \n",
    "        for line in f:\n",
    "            topicData = line.split(\"\\t\")\n",
    "            topicKey = topicData[0]\n",
    "            topicTerms = topicData[1]\n",
    "            ratings = topicData[2]\n",
    "            reasons = topicData[3]\n",
    "            \n",
    "            try:\n",
    "                ratings = list(map(lambda x: int(x.strip().replace(\"'\", \"\")), ratings.replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")))\n",
    "                ratings = np.array(ratings)\n",
    "                tweetsMap[topicKey][\"mean\"] = np.mean(ratings)\n",
    "                print(\"Inserting ratings for {}\".format(topicKey))\n",
    "                tweetsMap[topicKey][\"ratings\"] = ratings.tolist()\n",
    "                print(\"Success\")\n",
    "                print(\"Inserting mean for {}\".format(topicKey))\n",
    "                tweetsMap[topicKey][\"mean\"] = np.mean(ratings)\n",
    "                print(\"Success\")\n",
    "                topicMap = tweetsMap[topicKey]\n",
    "                print(topicMap[\"key\"], topicMap[\"mean\"])\n",
    "                json.dump(topicMap, output, sort_keys=True)\n",
    "                output.write(\"\\n\")\n",
    "            except:\n",
    "                print(\"{} is missing.\".format(topicKey))\n",
    "            \n",
    "            \n",
    "            \n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryConversion(outputFile):\n",
    "    labels = {}\n",
    "    with open(outputFile, 'r') as f:\n",
    "        for line in f:\n",
    "            tweet = json.loads(line)\n",
    "            if(tweet['mean'] >= 1.9):\n",
    "                labels[tweet['key']] = 1\n",
    "            elif(tweet['mean'] <= 1.467):\n",
    "                labels[tweet['key']] = 0\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Retweet and date\n",
    "def singleMessageFeatureExtraction(tweet_json):\n",
    "    #print(tweet_json)\n",
    "    retweets = 0\n",
    "    try:\n",
    "        retweets = tweet_json[\"tweet\"][\"retweet_status\"]\n",
    "        retweets = 1\n",
    "    except:\n",
    "        retweets = 0\n",
    "    date = tweet_json[\"tweet\"][\"created_at\"].split(\" \")[0]\n",
    "    dates = []\n",
    "    if date == \"Mon\":\n",
    "        dates = [1,0,0,0,0,0,0]\n",
    "    elif date == \"Tue\":\n",
    "        dates = [0,1,0,0,0,0,0]\n",
    "    elif date == \"Wed\":\n",
    "        dates = [0,0,1,0,0,0,0]\n",
    "    elif date == \"Thu\":\n",
    "        dates = [0,0,0,1,0,0,0]\n",
    "    elif date == \"Fri\":\n",
    "        dates = [0,0,0,0,1,0,0]\n",
    "    elif date == \"Sat\":\n",
    "        dates = [0,0,0,0,0,1,0]\n",
    "    elif date == \"Sun\":\n",
    "        dates = [0,0,0,0,0,0,1]\n",
    "    return retweets, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unshorten_url(url):\n",
    "    return requests.head(url, allow_redirects=True).url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structuralFeatureExtraction(topics):\n",
    "    tweetsFeatures = None\n",
    "    np.array(tweetsFeatures)\n",
    "    count = 0\n",
    "    for key in topics:\n",
    "        #print(\"Starting feature extraction for topic {} of {}\".format(count, len(topics)))\n",
    "        topicFeatures = []\n",
    "        \n",
    "        averageLength = 0\n",
    "        frequencyHashtags = 0\n",
    "        frequencyMedia = 0\n",
    "        frequencyMentions = 0\n",
    "        frequencyRetweets = 0\n",
    "        frequencyWebLinks = 0\n",
    "        \n",
    "        for tweet in topics[key]:\n",
    "            \n",
    "            #print(\"Extracting information from tweet \" + str(tweet['id']))\n",
    "            #Length of characters\n",
    "            #print(\"Adding Length of charactrs\")\n",
    "            averageLength = averageLength + len(tweet['tweet']['text'])\n",
    "            \n",
    "            #Frequency of Hashtags\n",
    "            #print(\"Adding frequency of Hashtags\")\n",
    "            frequencyHashtags = frequencyHashtags + len(tweet['tweet']['entities']['hashtags'])\n",
    "                                \n",
    "            #Frequency of Media\n",
    "            #print(\"Adding frequency of Media\")\n",
    "            #frequencyMedia = frequencyMedia + len(tweet['tweet']['entities']['media'])\n",
    "            \n",
    "            #Frequency of Mentions\n",
    "            #print(\"Adding Frequency of Mentions\")\n",
    "            frequencyMentions = frequencyMentions + len(tweet['tweet']['entities']['user_mentions'])\n",
    "            \n",
    "            #Frequency of Retweets\n",
    "            #print(\"Adding Frequency of Retweets\")\n",
    "            frequencyRetweets = frequencyRetweets\n",
    "            \n",
    "            #Frequency of Web Links\n",
    "            #print(\"Adding Frequency of Web Links\")\n",
    "            frequencyWebLinks = frequencyWebLinks + len(tweet['tweet']['entities']['urls'])\n",
    "        \n",
    "        #Appending features to list\n",
    "        topicFeatures.append(len(topics[key]))\n",
    "        topicFeatures.append(averageLength)\n",
    "        topicFeatures.append(averageLength/len(topics[key]))\n",
    "        topicFeatures.append(frequencyHashtags)\n",
    "        topicFeatures.append(frequencyHashtags/len(topics[key]))\n",
    "        topicFeatures.append(frequencyMedia)\n",
    "        topicFeatures.append(frequencyMedia/len(topics[key]))\n",
    "        topicFeatures.append(frequencyMentions)\n",
    "        topicFeatures.append(frequencyMentions/len(topics[key]))\n",
    "        topicFeatures.append(frequencyRetweets)\n",
    "        topicFeatures.append(frequencyRetweets/len(topics[key]))\n",
    "        topicFeatures.append(frequencyWebLinks)\n",
    "        topicFeatures.append(frequencyWebLinks/len(topics[key]))\n",
    "        \n",
    "        #Appending feataures to features array\n",
    "        topicFeatures = [topicFeatures]\n",
    "        if(count == 0):\n",
    "            tweetsFeatures = topicFeatures\n",
    "            #print(\"Length of array: {}\".format(len(tweetsFeatures[count])))\n",
    "        else:\n",
    "            tweetsFeatures = np.append(tweetsFeatures, topicFeatures, axis = 0)\n",
    "            #print(tweetsFeatures.shape)\n",
    "        \n",
    "        #print(\"Finished feature extraction\")\n",
    "        count += 1\n",
    "        \n",
    "    return tweetsFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentFeatureExtraction(topics):\n",
    "    \n",
    "    tweetsFeatures = None\n",
    "    np.array(tweetsFeatures)\n",
    "    \n",
    "    first = True\n",
    "    first_pronouns = set([\"i\", \"we\"])\n",
    "    second_pronouns = set([\"you\"])\n",
    "    third_pronouns = set([\"he\", \"him,\" \"she\", \"her\", \"they\", \"them\", \"it\"])\n",
    "    \n",
    "    count2 = 0\n",
    "    tweetsFeatures = np.array([])\n",
    "    #prop for proportion, fr for frequency \n",
    "    total_no_tweets = 0\n",
    "        \n",
    "    fr_quest_mark = 0\n",
    "    fr_excl_mark = 0\n",
    "\n",
    "    fr_emot_smile = 0 \n",
    "        \n",
    "    fr_tweets_hashtag = 0\n",
    "        \n",
    "    fr_pron_first = 0\n",
    "    fr_pron_sec = 0\n",
    "    fr_pron_third = 0\n",
    "        \n",
    "    #Polarity = Average sentiment score of tweets \n",
    "    avg_polarity = 0 \n",
    "    avg_objectivity = 0\n",
    "    disagreement = 0\n",
    "    \n",
    " \n",
    "    for topic in topics: \n",
    "        current_topic = topics[topic]\n",
    "        total_no_tweets = len(current_topic)\n",
    "        for tweet in current_topic: \n",
    "            split_tweet = tweet[\"tweet\"][\"text\"].split()\n",
    "            split_tweet_word = set(tweet[\"tweet\"][\"text\"].split(\" \"))\n",
    "\n",
    "            if '?' in split_tweet:\n",
    "                fr_quest_mark += 1\n",
    "            if '!' in split_tweet:\n",
    "                fr_excl_mark += 1\n",
    "            if '😊' in split_tweet:\n",
    "                fr_emot_smile += 1\n",
    "            if '#' in split_tweet:\n",
    "                fr_tweets_hashtag += 1\n",
    "            \n",
    "            if (first_pronouns & split_tweet_word):\n",
    "                fr_pron_first += 1\n",
    "            if (second_pronouns & split_tweet_word):\n",
    "                fr_pron_sec += 1\n",
    "            if (third_pronouns & split_tweet_word):\n",
    "                fr_pron_third += 1 \n",
    "                \n",
    "            \n",
    "            tweetSentiment = TextBlob(tweet[\"tweet\"][\"text\"])\n",
    "            sentimentScore = tweetSentiment.sentiment[0]\n",
    "            objectivityScore = tweetSentiment.sentiment[1]\n",
    "            avg_polarity += sentimentScore\n",
    "            avg_objectivity += objectivityScore\n",
    "                \n",
    "                \n",
    "                \n",
    "        prop_quest_mark = fr_quest_mark / total_no_tweets\n",
    "        prop_excl_mark = fr_excl_mark / total_no_tweets\n",
    "        prop_emot_smile = fr_emot_smile / total_no_tweets\n",
    "        prop_tweets_hashtag = fr_tweets_hashtag / total_no_tweets\n",
    "\n",
    "        \n",
    "        prop_pron_first = fr_pron_first / total_no_tweets\n",
    "        prop_pron_sec = fr_pron_sec / total_no_tweets\n",
    "        prop_pron_third = fr_pron_third / total_no_tweets\n",
    "        \n",
    "        avg_polarity = avg_polarity / total_no_tweets\n",
    "        avg_objectivity = avg_objectivity / total_no_tweets        \n",
    "           \n",
    "        disagreement = 0\n",
    "        current_topic_feature = []\n",
    "    \n",
    "        current_topic_feature.append(avg_polarity)\n",
    "        current_topic_feature.append(avg_objectivity)\n",
    "        current_topic_feature.append(disagreement)\n",
    "        current_topic_feature.append(fr_quest_mark)\n",
    "        current_topic_feature.append(prop_quest_mark)\n",
    "        current_topic_feature.append(fr_excl_mark)\n",
    "        current_topic_feature.append(prop_excl_mark)\n",
    "        current_topic_feature.append(fr_emot_smile)\n",
    "        current_topic_feature.append(prop_emot_smile)\n",
    "        current_topic_feature.append(fr_pron_first)\n",
    "        current_topic_feature.append(prop_pron_first)\n",
    "        current_topic_feature.append(fr_pron_sec)\n",
    "        current_topic_feature.append(prop_pron_sec)\n",
    "        current_topic_feature.append(fr_pron_third)\n",
    "        current_topic_feature.append(prop_pron_third)\n",
    "    \n",
    "        topicFeatures = [current_topic_feature]\n",
    "        if(count2 == 0):\n",
    "            tweetsFeatures = topicFeatures\n",
    "            print(\"Length of array: {}\".format(len(tweetsFeatures[count2])))\n",
    "        else:\n",
    "            tweetsFeatures = np.append(tweetsFeatures, topicFeatures, axis = 0)\n",
    "            print(tweetsFeatures.shape)\n",
    "        count2 = count2 + 1\n",
    "    \n",
    "    return tweetsFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userFeatureExtraction(topics):\n",
    "    tweetsFeatures = None\n",
    "    np.array(tweetsFeatures)\n",
    "    \n",
    "    first = True\n",
    "    userFeatures = None\n",
    "    count2 = 0\n",
    "    tweetsFeatures = np.array([])\n",
    "    #Avg date create\n",
    "    avg_date_user_create = 0\n",
    "        \n",
    "    #Average follower count\n",
    "    avg_follower_cnt = 0\n",
    "    \n",
    "    #Average friend count\n",
    "    avg_friend_cnt = 0 \n",
    "    \n",
    "    #Average authored status count \n",
    "    avg_aut_stat_cnt = 0\n",
    "    \n",
    "    #Frequency of verified author \n",
    "    fr_veri_aut = 0 \n",
    "    \n",
    "    #Author of the First Tweet is Verified\n",
    "    fr_first_veri = 0\n",
    "    \n",
    "        \n",
    "    avg_date_tweet_create = 0\n",
    "\n",
    "    for topic in topics:\n",
    "        no_tweet = len(topic)\n",
    "        for tweet in topics[topic]:\n",
    "            \n",
    "            #Average account age format : \"created_at\": \"Fri Jun 26 07:47:06 +0000 2009\"\n",
    "            user_created_string = tweet['tweet']['user']['created_at']\n",
    "            tweet_created_string = tweet['tweet']['created_at']\n",
    "            user_created_string_list = user_created_string.split(\" \")\n",
    "            tweet_created_string_list = tweet_created_string.split(\" \")\n",
    "            day_user = user_created_string_list[2]\n",
    "            month_user = 0\n",
    "            year_user = user_created_string_list[5]\n",
    "            \n",
    "            day_tweet = tweet_created_string_list[2]\n",
    "            month_tweet = 0\n",
    "            year_tweet = tweet_created_string_list[5]\n",
    "\n",
    "            if (user_created_string_list[1] == 'Jan'):\n",
    "                month_user = 1\n",
    "            elif (user_created_string_list[1] == 'Feb'):\n",
    "                month_user = 2\n",
    "            elif (user_created_string_list[1] == 'Mar'):\n",
    "                month_user = 3\n",
    "            elif (user_created_string_list[1] == 'Apr'):\n",
    "                month_user = 4\n",
    "            elif (user_created_string_list[1] == 'May'):\n",
    "                month_user = 5\n",
    "            elif (user_created_string_list[1] == 'Jun'):\n",
    "                month_user = 6\n",
    "            elif (user_created_string_list[1] == 'Jul'):\n",
    "                month_user = 7\n",
    "            elif (user_created_string_list[1] == 'Aug'):\n",
    "                month_user = 8\n",
    "            elif (user_created_string_list[1] == 'Sep'):\n",
    "                month_user = 9\n",
    "            elif (user_created_string_list[1] == 'Oct'):\n",
    "                month_user = 10\n",
    "            elif (user_created_string_list[1] == 'Nov'):\n",
    "                month_user = 11\n",
    "            elif (user_created_string_list[1] == 'Dec'):\n",
    "                month_user = 12\n",
    "                \n",
    "                \n",
    "            if (tweet_created_string_list[1] == 'Jan'):\n",
    "                month_tweet = 1\n",
    "            elif (tweet_created_string_list[1] == 'Feb'):\n",
    "                month_tweet = 2\n",
    "            elif (tweet_created_string_list[1] == 'Mar'):\n",
    "                month_tweet = 3\n",
    "            elif (tweet_created_string_list[1] == 'Apr'):\n",
    "                month_tweet = 4\n",
    "            elif (tweet_created_string_list[1] == 'May'):\n",
    "                month_tweet = 5\n",
    "            elif (tweet_created_string_list[1] == 'Jun'):\n",
    "                month_tweet = 6\n",
    "            elif (tweet_created_string_list[1] == 'Jul'):\n",
    "                month_tweet = 7\n",
    "            elif (tweet_created_string_list[1] == 'Aug'):\n",
    "                month_tweet = 8\n",
    "            elif (tweet_created_string_list[1] == 'Sep'):\n",
    "                month_tweet = 9\n",
    "            elif (tweet_created_string_list[1] == 'Oct'):\n",
    "                month_tweet = 10\n",
    "            elif (tweet_created_string_list[1] == 'Nov'):\n",
    "                month_tweet = 11\n",
    "            elif (tweet_created_string_list[1] == 'Dec'):\n",
    "                month_tweet = 12\n",
    "            \n",
    "            user_created_date = date(int(year_user),int(month_user),int(day_user))\n",
    "            tweet_created_date = date(int(year_tweet),int(month_tweet),int(day_tweet))\n",
    "            current_date = date.today()\n",
    "            user_delta = current_date - user_created_date\n",
    "            tweet_delta = current_date - tweet_created_date\n",
    "            avg_date_user_create += user_delta.days\n",
    "            avg_date_tweet_create += tweet_delta.days\n",
    "            \n",
    "            \n",
    "            \n",
    "            follower_count = tweet['tweet']['user']['followers_count']\n",
    "        \n",
    "            friend_count = tweet['tweet']['user']['friends_count']\n",
    "        \n",
    "            aut_stat_count = tweet['tweet']['user']['statuses_count']\n",
    "        \n",
    "            #0 for false, 1 for true\n",
    "            is_verified = 0\n",
    "        \n",
    "            if (tweet['tweet']['user']['verified'] == True):\n",
    "                is_verified = 1\n",
    "            else:\n",
    "                is_verified = 0\n",
    "            \n",
    "            if (tweet['tweet']['in_reply_to_status_id'] != None) and (tweet['tweet']['user']['verified'] == True):\n",
    "                fr_first_veri += 1\n",
    "            \n",
    "                                                                      \n",
    "            avg_follower_cnt += follower_count\n",
    "            avg_friend_cnt += friend_count\n",
    "            avg_aut_stat_cnt += aut_stat_count\n",
    "            fr_veri_aut += is_verified\n",
    "                                     \n",
    "        G = nx.Graph()\n",
    "        current_users = []\n",
    "                                                                    \n",
    "        for tweet in topics[topic]:\n",
    "            if tweet['tweet']['user']['id'] not in current_users:\n",
    "                current_users.append(tweet['tweet']['user']['id'])\n",
    "                G.add_node(tweet['tweet']['user']['id'])                  \n",
    "                                                                    \n",
    "        for tweet in topics[topic]:\n",
    "            for i in tweet['tweet']['entities']['user_mentions']:\n",
    "                mention_id = i['id']\n",
    "                G.add_edge(tweet['tweet']['user']['id'], mention_id)\n",
    "    \n",
    "            if 'retweeted_status' in i:\n",
    "                retweet_id = i['tweet']['retweeted_status']['id']\n",
    "                G.add_edge(tweet['tweet']['user']['id'], retweet_id)                                        \n",
    "                                                                    \n",
    "                                                                      \n",
    "        avg_date_user_create = avg_date_user_create / no_tweet                                                              \n",
    "        avg_follower_cnt = avg_follower_cnt / no_tweet\n",
    "        avg_friend_cnt = avg_friend_cnt / no_tweet\n",
    "        avg_aut_stat_cnt = avg_aut_stat_cnt / no_tweet\n",
    "        avg_date_tweet_create = avg_date_tweet_create / no_tweet                                                    \n",
    "        \n",
    "        current_topic_feature = []\n",
    "        \n",
    "        current_topic_feature.append(avg_date_user_create)                                                              \n",
    "        current_topic_feature.append(avg_follower_cnt)\n",
    "        current_topic_feature.append(avg_friend_cnt)\n",
    "        current_topic_feature.append(avg_aut_stat_cnt)\n",
    "        current_topic_feature.append(fr_veri_aut)\n",
    "        current_topic_feature.append(fr_first_veri)\n",
    "        current_topic_feature.append(density(G)) \n",
    "\n",
    "        print(\"Current topic extracted features: \")\n",
    "        print(avg_date_user_create)\n",
    "        print(avg_follower_cnt)\n",
    "        print(avg_friend_cnt)\n",
    "        print(avg_aut_stat_cnt)\n",
    "        print(fr_veri_aut)\n",
    "        print(fr_first_veri)\n",
    "        print(density(G))\n",
    "        print()\n",
    "        \n",
    "        topicFeatures = [current_topic_feature]\n",
    "        if(count2 == 0):\n",
    "            tweetsFeatures = topicFeatures\n",
    "            print(\"Length of array: {}\".format(len(tweetsFeatures[count2])))\n",
    "        else:\n",
    "            tweetsFeatures = np.append(tweetsFeatures, topicFeatures, axis = 0)\n",
    "            print(tweetsFeatures.shape)\n",
    "        count2 = count2 + 1\n",
    "    \n",
    "    return tweetsFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalFeatureExtraction(topics):\n",
    "    \n",
    "    \n",
    "    firstArray = True\n",
    "    tweetsFeatures = np.array([])\n",
    "    firstAppend = True\n",
    "    count  = 1\n",
    "    \n",
    "    #Go through each event and create the features \n",
    "    for k in topics:\n",
    "#         print(\"Event: \" + str(count))\n",
    "        count = count + 1\n",
    "        #Sort tweets\n",
    "        sortedArray = sorted(topics[k], key=lambda x: datetime.strptime(x['tweet']['created_at'],\"%a %b %d %H:%M:%S +0000 %Y\"))\n",
    "#         for tweet in sortedArray:\n",
    "#             print(tweet['tweet']['created_at'])\n",
    "        #Create values\n",
    "        first = True\n",
    "        time = 0\n",
    "        age = 0\n",
    "        difference = 0\n",
    "        followers = 0\n",
    "        friends = 0\n",
    "        status = 0\n",
    "        perMin = 0\n",
    "        timePiece = 0\n",
    "        \n",
    "        #Create arrays\n",
    "        \n",
    "        currentAge = []\n",
    "        currentDifference = []\n",
    "        currentFollowers = []\n",
    "        currentFriends = []\n",
    "        currentStatus = []\n",
    "        currentPerMin = []\n",
    "        timePeriod = []\n",
    "        \n",
    "        #Go through tweets in the event\n",
    "        for tweet in sortedArray:\n",
    "            \n",
    "            #If it is the first time\n",
    "            if(first == True):\n",
    "                #Set beginning time\n",
    "                time = timeConvert(tweet['tweet']['created_at'])\n",
    "                \n",
    "                followers, friends, status, perMin = addTempFeatures(followers, friends, status, perMin, tweet)\n",
    "  \n",
    "            #If the current time in in the 60 seconds interval of the first time and if the time is also greater than the first time\n",
    "            if((timeConvert(tweet['tweet']['created_at']) - time) < 60 and (timeConvert(tweet['tweet']['created_at']) >= time)):\n",
    "                \n",
    "                followers, friends, status, perMin = addTempFeatures(followers, friends, status, perMin, tweet)\n",
    "\n",
    "                first = False\n",
    "                \n",
    "            #If the current time is of past 00:00 when the start time was before that\n",
    "            elif(timeConvert(tweet['tweet']['created_at']) < time):\n",
    "                \n",
    "                if(((time + timeConvert(tweet['tweet']['created_at'])) - time) < 60) :\n",
    "                    \n",
    "                    followers, friends, status, perMin = addTempFeatures(followers, friends, status, perMin, tweet)\n",
    "                    first = False\n",
    "                else:\n",
    "                     #Convert values to log space\n",
    "#                     if(perMin == 0):\n",
    "#                         print(\"Set: {}, {}, {}, {}\".format(followers, friends, status, perMin))\n",
    "#                         print(time)\n",
    "#                         print(tweet['tweet']['created_at'])\n",
    "                    if(followers>0):\n",
    "                        currentFollowers.append(math.log(followers))\n",
    "                    else:\n",
    "                        currentFollowers.append(followers)\n",
    "                    if(friends > 0):\n",
    "                        currentFriends.append(math.log(friends))\n",
    "                    else:\n",
    "                        currentFriends.append(friends)\n",
    "                    if(status > 0):\n",
    "                        currentStatus.append(math.log(status))\n",
    "                    else:\n",
    "                        currentStatus.append(status)\n",
    "                    currentPerMin.append(math.log(perMin))\n",
    "                    timePeriod.append(timePiece+1)\n",
    "                    #print(\"1 success\")\n",
    "                    #Set new beginning time\n",
    "                    time = timeConvert(tweet['tweet']['created_at'])\n",
    "                    age = 0\n",
    "                    difference = 0\n",
    "                    followers = 0\n",
    "                    friends = 0\n",
    "                    status = 0\n",
    "                    perMin = 0\n",
    "                    followers, friends, status, perMin = addTempFeatures(followers, friends, status, perMin, tweet)\n",
    "\n",
    "            #Change the start time to a new value\n",
    "            else:\n",
    "                #Convert values to log space\n",
    "                #if(perMin == 0):\n",
    "                    #print(\"Set: {}, {}, {}, {}\".format(followers, friends, status, perMin))\n",
    "                    ##print(time)\n",
    "\n",
    "                    ###print(tweet['tweet']['created_at'])\n",
    "\n",
    "                if(followers>0):\n",
    "                    currentFollowers.append(math.log(followers))\n",
    "                else:\n",
    "                    currentFollowers.append(followers)\n",
    "                if(friends > 0):\n",
    "                    currentFriends.append(math.log(friends))\n",
    "                else:\n",
    "                    currentFriends.append(friends)\n",
    "                if(status > 0):\n",
    "                    currentStatus.append(math.log(status))\n",
    "                else:\n",
    "                    currentStatus.append(status)\n",
    "                currentPerMin.append(math.log(perMin))\n",
    "                timePeriod.append(timePiece+1)\n",
    "                #print('2 success')\n",
    "                #Set new beginning time\n",
    "                time = timeConvert(tweet['tweet']['created_at'])\n",
    "                age = 0\n",
    "                difference = 0\n",
    "                followers = 0\n",
    "                friends = 0\n",
    "                status = 0\n",
    "                perMin = 0\n",
    "                followers, friends, status, perMin = addTempFeatures(followers, friends, status, perMin, tweet)\n",
    "            \n",
    "            #print(\"Set: {}, {}, {}, {}\".format(followers, friends, status, perMin))\n",
    "            if(len(sortedArray) == 1):\n",
    "                if(followers>0):\n",
    "                    currentFollowers.append(math.log(followers))\n",
    "                else:\n",
    "                    currentFollowers.append(followers)\n",
    "                if(friends > 0):\n",
    "                    currentFriends.append(math.log(friends))\n",
    "                else:\n",
    "                    currentFriends.append(friends)\n",
    "                if(status > 0):\n",
    "                    currentStatus.append(math.log(status))\n",
    "                else:\n",
    "                    currentStatus.append(status)\n",
    "                currentPerMin.append(math.log(perMin))\n",
    "                timePeriod.append(timePiece+1)\n",
    "                #print(\"3 success\")\n",
    "        #Current logistic regression model, get slope, and append to the event features list\n",
    "\n",
    "        current_topic_features = []\n",
    "        followersModel = LinearRegression()\n",
    "        followersModel.fit(np.array(currentFollowers).reshape(-1, 1), timePeriod)\n",
    "        current_topic_features.append(followersModel.coef_)\n",
    "        \n",
    "        friendsModel = LinearRegression()\n",
    "        friendsModel.fit(np.array(currentFriends).reshape(-1, 1), timePeriod)\n",
    "        current_topic_features.append(friendsModel.coef_)\n",
    "        \n",
    "        statusModel = LinearRegression()\n",
    "        statusModel.fit(np.array(currentStatus).reshape(-1, 1), timePeriod)\n",
    "        current_topic_features.append(statusModel.coef_)\n",
    "        \n",
    "        perMinModel = LinearRegression()\n",
    "        perMinModel.fit(np.array(currentPerMin).reshape(-1, 1), timePeriod)\n",
    "        current_topic_features.append(perMinModel.coef_)\n",
    "        \n",
    "        #Create the feature matrix\n",
    "        topicFeatures = [current_topic_features]\n",
    "        if(firstAppend == True):\n",
    "            tweetsFeatures = topicFeatures\n",
    "        else:\n",
    "            tweetsFeatures = np.append(tweetsFeatures, topicFeatures, axis = 0)\n",
    "#             print(tweetsFeatures.shape)\n",
    "        firstAppend = False\n",
    "               \n",
    "    return tweetsFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTime(topics):\n",
    "    first = True\n",
    "    count = 1\n",
    "    for k in topics:\n",
    "    \n",
    "        #Sort tweets\n",
    "        sortedArray = sorted(topics[k], key=lambda x: datetime.strptime(x['tweet']['created_at'],\"%a %b %d %H:%M:%S +0000 %Y\"))\n",
    "\n",
    "        #Create values\n",
    "        time = 0\n",
    "        for tweet in sortedArray:\n",
    "\n",
    "            #If it is the first time\n",
    "            if(first == True):\n",
    "                #Set beginning time\n",
    "                print(\"Section: \" + str(count))\n",
    "                time = timeConvert(tweet['tweet']['created_at'])\n",
    "                print(tweet['tweet']['created_at'])\n",
    "            if((timeConvert(tweet['tweet']['created_at']) - time) < 60 and (timeConvert(tweet['tweet']['created_at']) >= time)):\n",
    "                print(tweet['tweet']['created_at'])\n",
    "                first = False\n",
    "            elif(timeConvert(tweet['tweet']['created_at']) < time):\n",
    "                \n",
    "                if(((time + timeConvert(tweet['tweet']['created_at'])) - time) < 60) :\n",
    "                    print(tweet['tweet']['created_at'])\n",
    "                    first = False\n",
    "                else:\n",
    "                    print(\"\")\n",
    "                    print(\"Section: \" + str(count))\n",
    "                    print(tweet['tweet']['created_at'])\n",
    "                    time = timeConvert(tweet['tweet']['created_at'])\n",
    "            else:\n",
    "                print(\"\")\n",
    "                print(\"Section: \" + str(count))\n",
    "                print(tweet['tweet']['created_at'])\n",
    "                time = timeConvert(tweet['tweet']['created_at'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTempFeatures(followers, friends, status, perMin, tweet):\n",
    "    #Account Age\n",
    "            \n",
    "    #Difference Between account age and tw/publications/eet publication time\n",
    "            \n",
    "    #Author's Follower\n",
    "    followers = followers + tweet['tweet']['user'][\"followers_count\"]\n",
    "\n",
    "    #Author's Friends\n",
    "    friends = friends + tweet['tweet']['user'][\"friends_count\"]\n",
    "\n",
    "    #Author's Statuses\n",
    "    status = status\n",
    "    if(tweet['tweet']['user'][\"verified\"] == \"True\"):\n",
    "        status = status + 1\n",
    "           \n",
    "    #Number of tweets per minute\n",
    "    perMin = perMin + 1\n",
    "    \n",
    "    return followers, friends, status, perMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveFeatures(topics):\n",
    "    structuralArray = structuralFeatureExtraction(topics)\n",
    "    contentArray = contentFeatureExtraction(topics)\n",
    "    userArray = userFeatureExtraction(topics)\n",
    "    temporalArray = temporalFeatureExtraction(topics)\n",
    "    \n",
    "    featureArray = np.concatenate(structuralArray, contentArray, userArray, temporalArray)\n",
    "    \n",
    "    return featureArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeConvert(time):\n",
    "    time = datetime.strptime(time, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "    return timedelta(hours = time.hour).seconds + timedelta(minutes = time.minute).seconds + time.second"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
